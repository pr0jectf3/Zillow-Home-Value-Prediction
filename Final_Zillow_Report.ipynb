{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, auc, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2985217, 58)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_properties = pd.read_csv('./properties_2017.csv', low_memory=False)\n",
    "df_properties.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77613, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train =  pd.read_csv('./train_2017.csv')\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>airconditioningtypeid</th>\n",
       "      <th>architecturalstyletypeid</th>\n",
       "      <th>basementsqft</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>buildingclasstypeid</th>\n",
       "      <th>buildingqualitytypeid</th>\n",
       "      <th>calculatedbathnbr</th>\n",
       "      <th>decktypeid</th>\n",
       "      <th>...</th>\n",
       "      <th>numberofstories</th>\n",
       "      <th>fireplaceflag</th>\n",
       "      <th>structuretaxvaluedollarcnt</th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>assessmentyear</th>\n",
       "      <th>landtaxvaluedollarcnt</th>\n",
       "      <th>taxamount</th>\n",
       "      <th>taxdelinquencyflag</th>\n",
       "      <th>taxdelinquencyyear</th>\n",
       "      <th>censustractandblock</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>10754147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>10759547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>27516.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>10843547</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>660680.0</td>\n",
       "      <td>1434941.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>774261.0</td>\n",
       "      <td>20800.37</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10859147</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>580059.0</td>\n",
       "      <td>1174475.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>594416.0</td>\n",
       "      <td>14557.57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10879947</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196751.0</td>\n",
       "      <td>440101.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>243350.0</td>\n",
       "      <td>5725.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  airconditioningtypeid  architecturalstyletypeid  basementsqft  \\\n",
       "0  10754147                    NaN                       NaN           NaN   \n",
       "1  10759547                    NaN                       NaN           NaN   \n",
       "2  10843547                    NaN                       NaN           NaN   \n",
       "3  10859147                    NaN                       NaN           NaN   \n",
       "4  10879947                    NaN                       NaN           NaN   \n",
       "\n",
       "   bathroomcnt  bedroomcnt  buildingclasstypeid  buildingqualitytypeid  \\\n",
       "0          0.0         0.0                  NaN                    NaN   \n",
       "1          0.0         0.0                  NaN                    NaN   \n",
       "2          0.0         0.0                  5.0                    NaN   \n",
       "3          0.0         0.0                  3.0                    6.0   \n",
       "4          0.0         0.0                  4.0                    NaN   \n",
       "\n",
       "   calculatedbathnbr  decktypeid  ...  numberofstories  fireplaceflag  \\\n",
       "0                NaN         NaN  ...              NaN            NaN   \n",
       "1                NaN         NaN  ...              NaN            NaN   \n",
       "2                NaN         NaN  ...              1.0            NaN   \n",
       "3                NaN         NaN  ...              1.0            NaN   \n",
       "4                NaN         NaN  ...              1.0            NaN   \n",
       "\n",
       "   structuretaxvaluedollarcnt  taxvaluedollarcnt  assessmentyear  \\\n",
       "0                         NaN                9.0          2016.0   \n",
       "1                         NaN            27516.0          2015.0   \n",
       "2                    660680.0          1434941.0          2016.0   \n",
       "3                    580059.0          1174475.0          2016.0   \n",
       "4                    196751.0           440101.0          2016.0   \n",
       "\n",
       "   landtaxvaluedollarcnt  taxamount  taxdelinquencyflag  taxdelinquencyyear  \\\n",
       "0                    9.0        NaN                 NaN                 NaN   \n",
       "1                27516.0        NaN                 NaN                 NaN   \n",
       "2               774261.0   20800.37                 NaN                 NaN   \n",
       "3               594416.0   14557.57                 NaN                 NaN   \n",
       "4               243350.0    5725.17                 NaN                 NaN   \n",
       "\n",
       "   censustractandblock  \n",
       "0                  NaN  \n",
       "1                  NaN  \n",
       "2                  NaN  \n",
       "3                  NaN  \n",
       "4                  NaN  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_properties.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>parcelid</th>\n",
       "      <th>logerror</th>\n",
       "      <th>transactiondate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>14297519</td>\n",
       "      <td>0.025595</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>17052889</td>\n",
       "      <td>0.055619</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>14186244</td>\n",
       "      <td>0.005383</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>12177905</td>\n",
       "      <td>-0.103410</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>10887214</td>\n",
       "      <td>0.006940</td>\n",
       "      <td>2017-01-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   parcelid  logerror transactiondate\n",
       "0  14297519  0.025595      2017-01-01\n",
       "1  17052889  0.055619      2017-01-01\n",
       "2  14186244  0.005383      2017-01-01\n",
       "3  12177905 -0.103410      2017-01-01\n",
       "4  10887214  0.006940      2017-01-01"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77613, 60)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since theres a large amount of differences in entries\n",
    "# We merge it, to reduce the amount of entries we don't need\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "joined_data_set.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77613, 58)\n",
      "(77613, 3)\n"
     ]
    }
   ],
   "source": [
    "# Now we take the data apart so we have usable data\n",
    "X = joined_data_set[df_properties.keys()]\n",
    "print(X.shape)\n",
    "\n",
    "y = joined_data_set[df_train.keys()]\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(77613, 52)\n",
      "(77613, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Now we remove data thats hard to work with\n",
    "y = y.drop('transactiondate', 1)\n",
    "y = y.drop('parcelid', 1)\n",
    "\n",
    "# Replacing NaN for all\n",
    "X = X.fillna(0)\n",
    "\n",
    "X = X.drop('hashottuborspa', 1)\n",
    "X = X.drop('propertycountylandusecode', 1)\n",
    "X = X.drop('propertyzoningdesc', 1)\n",
    "X = X.drop('fireplaceflag', 1)\n",
    "X = X.drop('taxdelinquencyflag', 1)\n",
    "X = X.drop('parcelid', 1)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "# And scale\n",
    "X = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting into Testing and Training Data\n",
    "testSize = 0.25\n",
    "randomState = 100\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Regression Methods\n",
    "my_linreg = linear_model.LinearRegression()\n",
    "my_ridge = linear_model.Ridge(alpha=.5)\n",
    "my_ridge_cv = linear_model.RidgeCV(alphas=np.logspace(-6, 6, 13))\n",
    "my_lassolars = linear_model.LassoLars(alpha=.1)\n",
    "my_lassolars_cv = linear_model.LassoLarsCV(cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training Models\n",
    "my_linreg.fit(X_train, y_train)\n",
    "my_ridge.fit(X_train, y_train)\n",
    "my_ridge_cv.fit(X_train, y_train)\n",
    "my_lassolars.fit(X_train, y_train)\n",
    "my_lassolars_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test)\n",
    "my_ridge_pred = my_ridge.predict(X_test)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  0.17662309017944727\n",
      "RSME Value Using Ridge Regression:  0.17661671553509561\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.17623084579531348\n",
      "RSME Value Using Lasso Lars:  0.17642723889508136\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.17620702919334602\n"
     ]
    }
   ],
   "source": [
    "# Calculating RMSE\n",
    "mse_linreg = metrics.mean_squared_error(y_test, my_linreg_pred)\n",
    "mse_ridge = metrics.mean_squared_error(y_test, my_ridge_pred)\n",
    "mse_ridge_cv = metrics.mean_squared_error(y_test, my_ridge_cv_pred)\n",
    "mse_lassolars = metrics.mean_squared_error(y_test, my_lassolars_pred)\n",
    "mse_lassolars_cv = metrics.mean_squared_error(y_test, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg = np.sqrt(mse_linreg)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "rmse_ridge_cv = np.sqrt(mse_ridge_cv)\n",
    "rmse_lassolars = np.sqrt(mse_lassolars)\n",
    "rmse_lassolars_cv = np.sqrt(mse_lassolars_cv)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(90275, 3)\n"
     ]
    }
   ],
   "source": [
    "# What happens if we use the 2016 data?\n",
    "df_properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2016_v2.csv')\n",
    "print(df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90275, 60)\n",
      "(90275, 58)\n",
      "(90275, 3)\n",
      "(90275, 52)\n",
      "(90275, 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "# Going through the same procedures\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_2 = joined_data_set[df_properties.keys()]\n",
    "print(X_2.shape)\n",
    "\n",
    "y_2 = joined_data_set[df_train.keys()]\n",
    "print(y_2.shape)\n",
    "\n",
    "# Now we remove data thats hard to work with\n",
    "y_2 = y_2.drop('transactiondate', 1)\n",
    "y_2 = y_2.drop('parcelid', 1)\n",
    "\n",
    "# Replacing NaN for all\n",
    "X_2 = X_2.fillna(0)\n",
    "\n",
    "X_2 = X_2.drop('hashottuborspa', 1)\n",
    "X_2 = X_2.drop('propertycountylandusecode', 1)\n",
    "X_2 = X_2.drop('propertyzoningdesc', 1)\n",
    "X_2 = X_2.drop('fireplaceflag', 1)\n",
    "X_2 = X_2.drop('taxdelinquencyflag', 1)\n",
    "X_2 = X_2.drop('parcelid', 1)\n",
    "\n",
    "print(X_2.shape)\n",
    "print(y_2.shape)\n",
    "\n",
    "# And scale\n",
    "X_2 = preprocessing.scale(X_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.25\n",
    "randomState = 100\n",
    "X_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg.fit(X_train_2, y_train_2)\n",
    "my_ridge.fit(X_train_2, y_train_2)\n",
    "my_ridge_cv.fit(X_train_2, y_train_2)\n",
    "my_lassolars.fit(X_train_2, y_train_2)\n",
    "my_lassolars_cv.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test_2)\n",
    "my_ridge_pred = my_ridge.predict(X_test_2)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test_2)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test_2)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  0.16545118543063186\n",
      "RSME Value Using Ridge Regression:  0.1654522451965398\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.16537956889615604\n",
      "RSME Value Using Lasso Lars:  0.16574364014185616\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.1653608307445429\n"
     ]
    }
   ],
   "source": [
    "mse_linreg_2 = metrics.mean_squared_error(y_test_2, my_linreg_pred)\n",
    "mse_ridge_2 = metrics.mean_squared_error(y_test_2, my_ridge_pred)\n",
    "mse_ridge_cv_2 = metrics.mean_squared_error(y_test_2, my_ridge_cv_pred)\n",
    "mse_lassolars_2 = metrics.mean_squared_error(y_test_2, my_lassolars_pred)\n",
    "mse_lassolars_cv_2 = metrics.mean_squared_error(y_test_2, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg_2 = np.sqrt(mse_linreg_2)\n",
    "rmse_ridge_2 = np.sqrt(mse_ridge_2)\n",
    "rmse_ridge_cv_2 = np.sqrt(mse_ridge_cv_2)\n",
    "rmse_lassolars_2 = np.sqrt(mse_lassolars_2)\n",
    "rmse_lassolars_cv_2 = np.sqrt(mse_lassolars_cv_2)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg_2)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge_2)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv_2)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars_2)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets merge the data and see what happens\n",
    "X_test_c = np.concatenate((X_test, X_test_2))\n",
    "X_train_c = np.concatenate((X_train, X_train_2))\n",
    "y_test_c = np.concatenate((y_test, y_test_2))\n",
    "y_train_c = np.concatenate((y_train, y_train_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg.fit(X_train_c, y_train_c)\n",
    "my_ridge.fit(X_train_c, y_train_c)\n",
    "my_ridge_cv.fit(X_train_c, y_train_c)\n",
    "my_lassolars.fit(X_train_c, y_train_c)\n",
    "my_lassolars_cv.fit(X_train_c, y_train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test_c)\n",
    "my_ridge_pred = my_ridge.predict(X_test_c)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test_c)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test_c)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  0.17056420411775808\n",
      "RSME Value Using Ridge Regression:  0.1705647371245366\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.17053042956242923\n",
      "RSME Value Using Lasso Lars:  0.17079688665256818\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.17052868584471745\n"
     ]
    }
   ],
   "source": [
    "mse_linreg_c = metrics.mean_squared_error(y_test_c, my_linreg_pred)\n",
    "mse_ridge_c = metrics.mean_squared_error(y_test_c, my_ridge_pred)\n",
    "mse_ridge_cv_c = metrics.mean_squared_error(y_test_c, my_ridge_cv_pred)\n",
    "mse_lassolars_c = metrics.mean_squared_error(y_test_c, my_lassolars_pred)\n",
    "mse_lassolars_cv_c = metrics.mean_squared_error(y_test_c, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg_c = np.sqrt(mse_linreg_c)\n",
    "rmse_ridge_c = np.sqrt(mse_ridge_c)\n",
    "rmse_ridge_cv_c = np.sqrt(mse_ridge_cv_c)\n",
    "rmse_lassolars_c = np.sqrt(mse_lassolars_c)\n",
    "rmse_lassolars_cv_c = np.sqrt(mse_lassolars_cv_c)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg_c)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge_c)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv_c)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars_c)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(77613, 3)\n",
      "(77613, 60)\n",
      "(77613, 58)\n",
      "(77613, 3)\n"
     ]
    }
   ],
   "source": [
    "#now with the merged data lets take out ouliers with a zscore greater than 3\n",
    "#load all data again\n",
    "df_properties = pd.read_csv('./properties_2017.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2017.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z = joined_data_set[df_properties.keys()]\n",
    "print(X_z.shape)\n",
    "\n",
    "y_z = joined_data_set[df_train.keys()]\n",
    "print(y_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(90275, 3)\n",
      "(90275, 60)\n",
      "(90275, 58)\n",
      "(90275, 3)\n"
     ]
    }
   ],
   "source": [
    "df_properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2016_v2.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z_temp = joined_data_set[df_properties.keys()]\n",
    "print(X_z_temp.shape)\n",
    "\n",
    "y_z_temp = joined_data_set[df_train.keys()]\n",
    "print(y_z_temp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167888, 58)\n",
      "(167888, 3)\n"
     ]
    }
   ],
   "source": [
    "X_z = X_z.append(X_z_temp)\n",
    "X_z = X_z.fillna(0)\n",
    "y_z = y_z.append(y_z_temp)\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167888, 53)\n",
      "(167888, 2)\n"
     ]
    }
   ],
   "source": [
    "# Now we remove data thats hard to work with\n",
    "y_z = y_z.drop('transactiondate', 1)\n",
    "\n",
    "\n",
    "X_z = X_z.drop('hashottuborspa', 1)\n",
    "X_z = X_z.drop('propertycountylandusecode', 1)\n",
    "X_z = X_z.drop('propertyzoningdesc', 1)\n",
    "X_z = X_z.drop('fireplaceflag', 1)\n",
    "X_z = X_z.drop('taxdelinquencyflag', 1)\n",
    "\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167888, 53)\n",
      "[[ 1.34600081  0.30880747  0.04954193 ...  0.51085951  0.1667827\n",
      "   0.20751942]\n",
      " [ 1.34625345  0.30880747  0.04954193 ...  0.06225182  0.1667827\n",
      "   0.20751943]\n",
      " [ 1.3503535   0.30880747  0.04954193 ...  0.41591069  0.1667827\n",
      "   0.2075201 ]\n",
      " ...\n",
      " [ 0.3266214   0.22244643  0.04954193 ...  0.12717605  0.1667827\n",
      "   0.04376241]\n",
      " [ 0.43618012  0.30880747  0.04954193 ...  0.90380087  0.1667827\n",
      "  13.35045316]\n",
      " [ 0.54416992  0.30880747  0.04954193 ...  0.07177166  0.1667827\n",
      "  13.35045316]]\n",
      "(127426, 53)\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "X_keys = X_z.keys()\n",
    "y_keys = y_z.keys()\n",
    "\n",
    "print(X_z.shape)\n",
    "z = np.abs(stats.zscore(X_z))\n",
    "print(z)\n",
    "X_z = X_z[(z < 3).all(axis=1)]\n",
    "print(X_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(131447, 53)\n",
      "(131447, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "joined_data_set = pd.merge(X_z, y_z)\n",
    "X_z = joined_data_set[X_keys]\n",
    "print(X_z.shape)\n",
    "y_z = joined_data_set[y_keys]\n",
    "print(y_z.shape)\n",
    "\n",
    "y_z = y_z.drop('parcelid', 1)\n",
    "X_z = X_z.drop('parcelid', 1)\n",
    "\n",
    "X_z = preprocessing.scale(X_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.25\n",
    "randomState = 100\n",
    "X_train_z, X_test_z, y_train_z, y_test_z = train_test_split(X_z, y_z, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.378e-07, with an active set of 25 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=6.238e-07, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=3.540e-07, with an active set of 28 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=4.088e-07, previous alpha=3.540e-07, with an active set of 28 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=6.244e-06, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.122e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 25 iterations, alpha=2.321e-06, previous alpha=2.230e-06, with an active set of 20 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=4.340e-06, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=2.731e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=2.694e-06, previous alpha=2.608e-06, with an active set of 14 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.199e-07, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.921e-07, with an active set of 32 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.403e-07, with an active set of 32 regressors, and the smallest cholesky pivot element being 4.829e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 33 iterations, alpha=2.997e-07, previous alpha=2.385e-07, with an active set of 32 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.209e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=6.043e-07, with an active set of 31 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 34 iterations, alpha=5.945e-07, previous alpha=5.857e-07, with an active set of 31 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.244e-06, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.398e-07, with an active set of 25 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.031e-07, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.731e-07, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.361e-07, with an active set of 27 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:604: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 28 iterations, alpha=7.949e-07, previous alpha=6.052e-07, with an active set of 27 regressors.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.140e-07, with an active set of 27 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=2.570e-07, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.497e-07, with an active set of 33 regressors, and the smallest cholesky pivot element being 1.825e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.196e-07, with an active set of 33 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=5.498e-07, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n",
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\least_angle.py:578: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=2.442e-07, with an active set of 31 regressors, and the smallest cholesky pivot element being 5.053e-08. Reduce max_iter or increase eps parameters.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg.fit(X_train_z, y_train_z)\n",
    "my_ridge.fit(X_train_z, y_train_z)\n",
    "my_ridge_cv.fit(X_train_z, y_train_z)\n",
    "my_lassolars.fit(X_train_z, y_train_z)\n",
    "my_lassolars_cv.fit(X_train_z, y_train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test_z)\n",
    "my_ridge_pred = my_ridge.predict(X_test_z)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test_z)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test_z)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  29460451433.668846\n",
      "RSME Value Using Ridge Regression:  0.1615783544013458\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.16159120033299065\n",
      "RSME Value Using Lasso Lars:  0.16202534780364442\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.16158560181522003\n"
     ]
    }
   ],
   "source": [
    "mse_linreg_z = metrics.mean_squared_error(y_test_z, my_linreg_pred)\n",
    "mse_ridge_z = metrics.mean_squared_error(y_test_z, my_ridge_pred)\n",
    "mse_ridge_cv_z = metrics.mean_squared_error(y_test_z, my_ridge_cv_pred)\n",
    "mse_lassolars_z = metrics.mean_squared_error(y_test_z, my_lassolars_pred)\n",
    "mse_lassolars_cv_z = metrics.mean_squared_error(y_test_z, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg_z = np.sqrt(mse_linreg_z)\n",
    "rmse_ridge_z = np.sqrt(mse_ridge_z)\n",
    "rmse_ridge_cv_z = np.sqrt(mse_ridge_cv_z)\n",
    "rmse_lassolars_z = np.sqrt(mse_lassolars_z)\n",
    "rmse_lassolars_cv_z = np.sqrt(mse_lassolars_cv_z)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg_z)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge_z)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv_z)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars_z)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(77613, 3)\n",
      "(77613, 60)\n",
      "(77613, 58)\n",
      "(77613, 3)\n",
      "(2985217, 58)\n",
      "(90275, 3)\n",
      "(90275, 60)\n",
      "(90275, 58)\n",
      "(90275, 3)\n",
      "(167888, 58)\n",
      "(167888, 3)\n",
      "(167888, 53)\n",
      "(167888, 2)\n"
     ]
    }
   ],
   "source": [
    "# Removing < 30% & doing z score\n",
    "df_properties = pd.read_csv('./properties_2017.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2017.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z = joined_data_set[df_properties.keys()]\n",
    "print(X_z.shape)\n",
    "\n",
    "y_z = joined_data_set[df_train.keys()]\n",
    "print(y_z.shape)\n",
    "\n",
    "df_properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2016_v2.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z_temp = joined_data_set[df_properties.keys()]\n",
    "print(X_z_temp.shape)\n",
    "\n",
    "y_z_temp = joined_data_set[df_train.keys()]\n",
    "print(y_z_temp.shape)\n",
    "\n",
    "X_z = X_z.append(X_z_temp)\n",
    "X_z = X_z.fillna(0)\n",
    "y_z = y_z.append(y_z_temp)\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)\n",
    "\n",
    "y_z = y_z.drop('transactiondate', 1)\n",
    "\n",
    "X_z = X_z.drop('hashottuborspa', 1)\n",
    "X_z = X_z.drop('propertycountylandusecode', 1)\n",
    "X_z = X_z.drop('propertyzoningdesc', 1)\n",
    "X_z = X_z.drop('fireplaceflag', 1)\n",
    "X_z = X_z.drop('taxdelinquencyflag', 1)\n",
    "\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try that again, but with the columns with the most 0's removed\n",
    "# to do this we are removing columns that have less than 30% valid entries\n",
    "# as dictated on the kaggle website\n",
    "\n",
    "X_z = X_z.drop('airconditioningtypeid', 1)\n",
    "X_z = X_z.drop('architecturalstyletypeid', 1)\n",
    "X_z = X_z.drop('basementsqft', 1)\n",
    "X_z = X_z.drop('buildingclasstypeid', 1)\n",
    "X_z = X_z.drop('decktypeid', 1)\n",
    "X_z = X_z.drop('finishedfloor1squarefeet', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet13', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet15', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet50', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet6', 1)\n",
    "X_z = X_z.drop('fireplacecnt', 1)\n",
    "X_z = X_z.drop('poolcnt', 1)\n",
    "X_z = X_z.drop('poolsizesum', 1)\n",
    "X_z = X_z.drop('pooltypeid10', 1)\n",
    "X_z = X_z.drop('pooltypeid2', 1)\n",
    "X_z = X_z.drop('pooltypeid7', 1)\n",
    "X_z = X_z.drop('storytypeid', 1)\n",
    "X_z = X_z.drop('threequarterbathnbr', 1)\n",
    "X_z = X_z.drop('typeconstructiontypeid', 1)\n",
    "X_z = X_z.drop('yardbuildingsqft17', 1)\n",
    "X_z = X_z.drop('yardbuildingsqft26', 1)\n",
    "X_z = X_z.drop('numberofstories', 1)\n",
    "X_z = X_z.drop('taxdelinquencyyear', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(167888, 30)\n",
      "[[1.34600081e+00 2.70878297e+00 8.33929950e-01 ... 1.84251290e-01\n",
      "  5.10859510e-01 2.07519425e-01]\n",
      " [1.34625345e+00 2.87439603e-01 3.57641279e-02 ... 3.70166726e-02\n",
      "  6.22518246e-02 2.07519430e-01]\n",
      " [1.35035350e+00 7.86810032e-01 3.57641279e-02 ... 4.38997043e-01\n",
      "  4.15910694e-01 2.07520101e-01]\n",
      " ...\n",
      " [3.26621404e-01 2.87439603e-01 9.05458205e-01 ... 4.89928423e-03\n",
      "  1.27176055e-01 4.37624114e-02]\n",
      " [4.36180116e-01 2.11930825e-01 3.57641279e-02 ... 1.20625388e+00\n",
      "  9.03800872e-01 1.33504532e+01]\n",
      " [5.44169923e-01 2.11930825e-01 3.57641279e-02 ... 1.22479642e-01\n",
      "  7.17716609e-02 1.33504532e+01]]\n",
      "(149522, 30)\n"
     ]
    }
   ],
   "source": [
    "X_keys = X_z.keys()\n",
    "y_keys = y_z.keys()\n",
    "\n",
    "print(X_z.shape)\n",
    "z = np.abs(stats.zscore(X_z))\n",
    "print(z)\n",
    "X_z = X_z[(z < 3).all(axis=1)]\n",
    "print(X_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(154248, 30)\n",
      "(154248, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "joined_data_set = pd.merge(X_z, y_z)\n",
    "X_z = joined_data_set[X_keys]\n",
    "print(X_z.shape)\n",
    "y_z = joined_data_set[y_keys]\n",
    "print(y_z.shape)\n",
    "\n",
    "y_z = y_z.drop('parcelid', 1)\n",
    "X_z = X_z.drop('parcelid', 1)\n",
    "\n",
    "X_z = preprocessing.scale(X_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.25\n",
    "randomState = 100\n",
    "X_train_z, X_test_z, y_train_z, y_test_z = train_test_split(X_z, y_z, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg.fit(X_train_z, y_train_z)\n",
    "my_ridge.fit(X_train_z, y_train_z)\n",
    "my_ridge_cv.fit(X_train_z, y_train_z)\n",
    "my_lassolars.fit(X_train_z, y_train_z)\n",
    "my_lassolars_cv.fit(X_train_z, y_train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test_z)\n",
    "my_ridge_pred = my_ridge.predict(X_test_z)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test_z)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test_z)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  0.15722339192212734\n",
      "RSME Value Using Ridge Regression:  0.15722185741150327\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.1572053480606298\n",
      "RSME Value Using Lasso Lars:  0.15752374665604352\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.15719744554080614\n"
     ]
    }
   ],
   "source": [
    "mse_linreg_z_c = metrics.mean_squared_error(y_test_z, my_linreg_pred)\n",
    "mse_ridge_z_c = metrics.mean_squared_error(y_test_z, my_ridge_pred)\n",
    "mse_ridge_cv_z_c = metrics.mean_squared_error(y_test_z, my_ridge_cv_pred)\n",
    "mse_lassolars_z_c = metrics.mean_squared_error(y_test_z, my_lassolars_pred)\n",
    "mse_lassolars_cv_z_c = metrics.mean_squared_error(y_test_z, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg_z_c = np.sqrt(mse_linreg_z_c)\n",
    "rmse_ridge_z_c = np.sqrt(mse_ridge_z_c)\n",
    "rmse_ridge_cv_z_c = np.sqrt(mse_ridge_cv_z_c)\n",
    "rmse_lassolars_z_c = np.sqrt(mse_lassolars_z_c)\n",
    "rmse_lassolars_cv_z_c = np.sqrt(mse_lassolars_cv_z_c)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg_z_c)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge_z_c)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv_z_c)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars_z_c)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv_z_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2985217, 58)\n",
      "(77613, 3)\n",
      "(77613, 60)\n",
      "(77613, 58)\n",
      "(77613, 3)\n",
      "(2985217, 58)\n",
      "(90275, 3)\n",
      "(90275, 60)\n",
      "(90275, 58)\n",
      "(90275, 3)\n",
      "(167888, 58)\n",
      "(167888, 3)\n",
      "(167888, 30)\n",
      "(167888, 2)\n"
     ]
    }
   ],
   "source": [
    "# Removing less than 30% and no zscore\n",
    "df_properties = pd.read_csv('./properties_2017.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2017.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z = joined_data_set[df_properties.keys()]\n",
    "print(X_z.shape)\n",
    "\n",
    "y_z = joined_data_set[df_train.keys()]\n",
    "print(y_z.shape)\n",
    "\n",
    "df_properties = pd.read_csv('./properties_2016.csv', low_memory=False)\n",
    "print(df_properties.shape)\n",
    "\n",
    "df_train =  pd.read_csv('./train_2016_v2.csv')\n",
    "print(df_train.shape)\n",
    "\n",
    "joined_data_set = pd.merge(df_properties, df_train)\n",
    "print(joined_data_set.shape)\n",
    "\n",
    "X_z_temp = joined_data_set[df_properties.keys()]\n",
    "print(X_z_temp.shape)\n",
    "\n",
    "y_z_temp = joined_data_set[df_train.keys()]\n",
    "print(y_z_temp.shape)\n",
    "\n",
    "X_z = X_z.append(X_z_temp)\n",
    "X_z = X_z.fillna(0)\n",
    "y_z = y_z.append(y_z_temp)\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)\n",
    "\n",
    "y_z = y_z.drop('transactiondate', 1)\n",
    "\n",
    "X_z = X_z.drop('hashottuborspa', 1)\n",
    "X_z = X_z.drop('propertycountylandusecode', 1)\n",
    "X_z = X_z.drop('propertyzoningdesc', 1)\n",
    "X_z = X_z.drop('fireplaceflag', 1)\n",
    "X_z = X_z.drop('taxdelinquencyflag', 1)\n",
    "X_z = X_z.drop('airconditioningtypeid', 1)\n",
    "X_z = X_z.drop('architecturalstyletypeid', 1)\n",
    "X_z = X_z.drop('basementsqft', 1)\n",
    "X_z = X_z.drop('buildingclasstypeid', 1)\n",
    "X_z = X_z.drop('decktypeid', 1)\n",
    "X_z = X_z.drop('finishedfloor1squarefeet', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet13', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet15', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet50', 1)\n",
    "X_z = X_z.drop('finishedsquarefeet6', 1)\n",
    "X_z = X_z.drop('fireplacecnt', 1)\n",
    "X_z = X_z.drop('poolcnt', 1)\n",
    "X_z = X_z.drop('poolsizesum', 1)\n",
    "X_z = X_z.drop('pooltypeid10', 1)\n",
    "X_z = X_z.drop('pooltypeid2', 1)\n",
    "X_z = X_z.drop('pooltypeid7', 1)\n",
    "X_z = X_z.drop('storytypeid', 1)\n",
    "X_z = X_z.drop('threequarterbathnbr', 1)\n",
    "X_z = X_z.drop('typeconstructiontypeid', 1)\n",
    "X_z = X_z.drop('yardbuildingsqft17', 1)\n",
    "X_z = X_z.drop('yardbuildingsqft26', 1)\n",
    "X_z = X_z.drop('numberofstories', 1)\n",
    "X_z = X_z.drop('taxdelinquencyyear', 1)\n",
    "\n",
    "print(X_z.shape)\n",
    "print(y_z.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(173262, 30)\n",
      "(173262, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:172: UserWarning: Numerical issues were encountered when centering the data and might not be solved. Dataset may contain too large values. You may need to prescale your features.\n",
      "  warnings.warn(\"Numerical issues were encountered \"\n"
     ]
    }
   ],
   "source": [
    "joined_data_set = pd.merge(X_z, y_z)\n",
    "X_z = joined_data_set[X_keys]\n",
    "print(X_z.shape)\n",
    "y_z = joined_data_set[y_keys]\n",
    "print(y_z.shape)\n",
    "\n",
    "y_z = y_z.drop('parcelid', 1)\n",
    "X_z = X_z.drop('parcelid', 1)\n",
    "\n",
    "X_z = preprocessing.scale(X_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "testSize = 0.25\n",
    "randomState = 100\n",
    "X_train_z, X_test_z, y_train_z, y_test_z = train_test_split(X_z, y_z, test_size=testSize, random_state=randomState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\carlo\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LassoLarsCV(copy_X=True, cv=10, eps=2.220446049250313e-16, fit_intercept=True,\n",
       "            max_iter=500, max_n_alphas=1000, n_jobs=None, normalize=True,\n",
       "            positive=False, precompute='auto', verbose=False)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_linreg.fit(X_train_z, y_train_z)\n",
    "my_ridge.fit(X_train_z, y_train_z)\n",
    "my_ridge_cv.fit(X_train_z, y_train_z)\n",
    "my_lassolars.fit(X_train_z, y_train_z)\n",
    "my_lassolars_cv.fit(X_train_z, y_train_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_linreg_pred = my_linreg.predict(X_test_z)\n",
    "my_ridge_pred = my_ridge.predict(X_test_z)\n",
    "my_ridge_cv_pred = my_ridge_cv.predict(X_test_z)\n",
    "my_lassolars_pred = my_lassolars.predict(X_test_z)\n",
    "my_lassolars_cv_pred = my_lassolars_cv.predict(X_test_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RSME Value Using Liear Regression:  0.16516719500418073\n",
      "RSME Value Using Ridge Regression:  0.16516484596171407\n",
      "RSME Value Using Ridge Regression Cross Validation:  0.16517446983538486\n",
      "RSME Value Using Lasso Lars:  0.1654748556924704\n",
      "RSME Value Using Lasso Lars Cross Validation:  0.16517835468886924\n"
     ]
    }
   ],
   "source": [
    "mse_linreg_z_c = metrics.mean_squared_error(y_test_z, my_linreg_pred)\n",
    "mse_ridge_z_c = metrics.mean_squared_error(y_test_z, my_ridge_pred)\n",
    "mse_ridge_cv_z_c = metrics.mean_squared_error(y_test_z, my_ridge_cv_pred)\n",
    "mse_lassolars_z_c = metrics.mean_squared_error(y_test_z, my_lassolars_pred)\n",
    "mse_lassolars_cv_z_c = metrics.mean_squared_error(y_test_z, my_lassolars_cv_pred)\n",
    "\n",
    "rmse_linreg_z_c = np.sqrt(mse_linreg_z_c)\n",
    "rmse_ridge_z_c = np.sqrt(mse_ridge_z_c)\n",
    "rmse_ridge_cv_z_c = np.sqrt(mse_ridge_cv_z_c)\n",
    "rmse_lassolars_z_c = np.sqrt(mse_lassolars_z_c)\n",
    "rmse_lassolars_cv_z_c = np.sqrt(mse_lassolars_cv_z_c)\n",
    "\n",
    "print(\"RSME Value Using Liear Regression: \", rmse_linreg_z_c)\n",
    "print(\"RSME Value Using Ridge Regression: \", rmse_ridge_z_c)\n",
    "print(\"RSME Value Using Ridge Regression Cross Validation: \", rmse_ridge_cv_z_c)\n",
    "print(\"RSME Value Using Lasso Lars: \", rmse_lassolars_z_c)\n",
    "print(\"RSME Value Using Lasso Lars Cross Validation: \", rmse_lassolars_cv_z_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
